{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eit</th>\n",
       "      <th>lasco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1996/5/1</td>\n",
       "      <td>C:/spaceweather/data/EIT/1996/5/1/01_01_48.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/1996/5/1/03_55_04.fts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996/5/1</td>\n",
       "      <td>C:/spaceweather/data/EIT/1996/5/1/09_54_10.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/1996/5/1/08_41_46.fts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996/5/1</td>\n",
       "      <td>C:/spaceweather/data/EIT/1996/5/1/18_32_56.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/1996/5/1/17_20_34.fts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1996/5/2</td>\n",
       "      <td>C:/spaceweather/data/EIT/1996/5/2/02_39_52.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/1996/5/2/01_11_29.fts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996/5/2</td>\n",
       "      <td>C:/spaceweather/data/EIT/1996/5/2/11_20_06.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/1996/5/2/09_51_41.fts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16674</th>\n",
       "      <td>2008/12/29</td>\n",
       "      <td>C:/spaceweather/data/EIT/2008/12/29/19_00_15.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/2008/12/29/19_31_44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16675</th>\n",
       "      <td>2008/12/30</td>\n",
       "      <td>C:/spaceweather/data/EIT/2008/12/30/01_00_13.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/2008/12/30/01_31_39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16676</th>\n",
       "      <td>2008/12/30</td>\n",
       "      <td>C:/spaceweather/data/EIT/2008/12/30/07_00_15.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/2008/12/30/07_31_39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16677</th>\n",
       "      <td>2008/12/30</td>\n",
       "      <td>C:/spaceweather/data/EIT/2008/12/30/13_00_13.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/2008/12/30/13_31_38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16678</th>\n",
       "      <td>2008/12/30</td>\n",
       "      <td>C:/spaceweather/data/EIT/2008/12/30/19_00_13.fts</td>\n",
       "      <td>C:/spaceweather/data/LASCO/2008/12/30/18_06_04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16679 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date                                               eit  \\\n",
       "0        1996/5/1    C:/spaceweather/data/EIT/1996/5/1/01_01_48.fts   \n",
       "1        1996/5/1    C:/spaceweather/data/EIT/1996/5/1/09_54_10.fts   \n",
       "2        1996/5/1    C:/spaceweather/data/EIT/1996/5/1/18_32_56.fts   \n",
       "3        1996/5/2    C:/spaceweather/data/EIT/1996/5/2/02_39_52.fts   \n",
       "4        1996/5/2    C:/spaceweather/data/EIT/1996/5/2/11_20_06.fts   \n",
       "...           ...                                               ...   \n",
       "16674  2008/12/29  C:/spaceweather/data/EIT/2008/12/29/19_00_15.fts   \n",
       "16675  2008/12/30  C:/spaceweather/data/EIT/2008/12/30/01_00_13.fts   \n",
       "16676  2008/12/30  C:/spaceweather/data/EIT/2008/12/30/07_00_15.fts   \n",
       "16677  2008/12/30  C:/spaceweather/data/EIT/2008/12/30/13_00_13.fts   \n",
       "16678  2008/12/30  C:/spaceweather/data/EIT/2008/12/30/19_00_13.fts   \n",
       "\n",
       "                                                   lasco  \n",
       "0       C:/spaceweather/data/LASCO/1996/5/1/03_55_04.fts  \n",
       "1       C:/spaceweather/data/LASCO/1996/5/1/08_41_46.fts  \n",
       "2       C:/spaceweather/data/LASCO/1996/5/1/17_20_34.fts  \n",
       "3       C:/spaceweather/data/LASCO/1996/5/2/01_11_29.fts  \n",
       "4       C:/spaceweather/data/LASCO/1996/5/2/09_51_41.fts  \n",
       "...                                                  ...  \n",
       "16674  C:/spaceweather/data/LASCO/2008/12/29/19_31_44...  \n",
       "16675  C:/spaceweather/data/LASCO/2008/12/30/01_31_39...  \n",
       "16676  C:/spaceweather/data/LASCO/2008/12/30/07_31_39...  \n",
       "16677  C:/spaceweather/data/LASCO/2008/12/30/13_31_38...  \n",
       "16678  C:/spaceweather/data/LASCO/2008/12/30/18_06_04...  \n",
       "\n",
       "[16679 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloc = pd.read_csv('C:/spaceweather/data/eit/eit.csv', names=['date','eit','lasco'])\n",
    "dataloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/spaceweather/data/EIT/1996/5/1/01_01_48.fts'\n",
      " 'C:/spaceweather/data/EIT/1996/5/1/09_54_10.fts'\n",
      " 'C:/spaceweather/data/EIT/1996/5/1/18_32_56.fts' ...\n",
      " 'C:/spaceweather/data/EIT/2008/12/30/07_00_15.fts'\n",
      " 'C:/spaceweather/data/EIT/2008/12/30/13_00_13.fts'\n",
      " 'C:/spaceweather/data/EIT/2008/12/30/19_00_13.fts']\n",
      "['C:/spaceweather/data/LASCO/1996/5/1/03_55_04.fts'\n",
      " 'C:/spaceweather/data/LASCO/1996/5/1/08_41_46.fts'\n",
      " 'C:/spaceweather/data/LASCO/1996/5/1/17_20_34.fts' ...\n",
      " 'C:/spaceweather/data/LASCO/2008/12/30/07_31_39.fts'\n",
      " 'C:/spaceweather/data/LASCO/2008/12/30/13_31_38.fts'\n",
      " 'C:/spaceweather/data/LASCO/2008/12/30/18_06_04.fts']\n"
     ]
    }
   ],
   "source": [
    "dataset = dataloc.values\n",
    "eit = dataset[:,1]\n",
    "lasco = dataset[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                               \\n#생성자 모델을 만듭니다.\\ngenerator = Sequential()\\n#노드 128\\ngenerator.add(Dense(128*4*4, input_dim=100, activation=LeakyReLU(0.2)))\\n#256 만들어야함 upsampling 2번(x4), input_dim은 100차원 벡터, 입력층에서 LeakyReLU\\ngenerator.add(BatchNormalization())\\ngenerator.add(Reshape((4, 4, 128)))\\ngenerator.add(UpSampling2D())\\n#업샘플링(가로세로x2)\\ngenerator.add(Conv2D(64, kernel_size=3, padding=\\'same\\'))\\ngenerator.add(BatchNormalization())\\ngenerator.add(Activation(LeakyReLU(0.2)))\\ngenerator.add(UpSampling2D())\\n#업샘플링(가로세로x2)\\ngenerator.add(Conv2D(1, kernel_size=3, padding=\\'same\\', activation=\\'tanh\\'))\\n#출력층에서 tanh\\n\\n#판별자 모델을 만듭니다.\\ndiscriminator = Sequential()\\ndiscriminator.add(Conv2D(64, kernel_size=3, strides=2, input_shape=(16,16,1), padding=\"same\"))\\ndiscriminator.add(Activation(LeakyReLU(0.2)))\\ndiscriminator.add(Dropout(0.3))\\n#노드 30% 꺼줌\\ndiscriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\\ndiscriminator.add(Activation(LeakyReLU(0.2)))\\ndiscriminator.add(Dropout(0.3))\\ndiscriminator.add(Flatten())\\n#2차원 1차원으로\\ndiscriminator.add(Dense(1, activation=\\'sigmoid\\'))\\ndiscriminator.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\')\\n#참 거짓 0~1로 구분\\ndiscriminator.trainable = False\\n\\n#생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\\nginput = Input(shape=(100,))\\ndis_output = discriminator(generator(ginput))\\ngan = Model(ginput, dis_output)\\ngan.compile(loss=\\'binary_crossentropy\\', optimizer=\\'adam\\')\\ngan.summary()\\n\\n#신경망을 실행시키는 함수를 만듭니다.\\ndef gan_train(epoch, batch_size, saving_interval):\\n    (X_train, _), (_, _) = lasco.load_data()\\n    X_train = X_train.reshape(X_train.shape[0], 16, 16, 1).astype(\\'float32\\')\\n    true = np.ones((batch_size, 1))\\n    fake = np.zeros((batch_size, 1))\\n\\n    for i in range(epoch):\\n        # 실제 데이터를 판별자에 입력하는 부분입니다.\\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\\n        imgs = X_train[idx]\\n        d_loss_real = discriminator.train_on_batch(imgs, true)\\n\\n        #가상 이미지를 판별자에 입력하는 부분입니다.\\n        noise = np.random.normal(0, 1, (batch_size, 100))\\n        gen_imgs = generator.predict(noise)\\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\\n\\n        #판별자와 생성자의 오차를 계산합니다.\\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\\n        g_loss = gan.train_on_batch(noise, true)\\n\\n        print(\\'epoch:%d\\' % i, \\' d_loss:%.4f\\' % d_loss, \\' g_loss:%.4f\\' % g_loss)\\n\\n        # 이부분은 중간 과정을 이미지로 저장해 주는 부분입니다. 본 장의 주요 내용과 관련이 없어\\n        # 소스코드만 첨부합니다. 만들어진 이미지들은 gan_images 폴더에 저장됩니다.\\n        if i % saving_interval == 0:\\n            #r, c = 5, 5\\n            noise = np.random.normal(0, 1, (25, 100))\\n            gen_imgs = generator.predict(noise)\\n\\n            # Rescale images 0 - 1\\n            gen_imgs = 0.5 * gen_imgs + 0.5\\n\\n            fig, axs = plt.subplots(5, 5)\\n            count = 0\\n            for j in range(5):\\n                for k in range(5):\\n                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap=\\'gray\\')\\n                    axs[j, k].axis(\\'off\\')\\n                    count += 1\\n            fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)\\n\\ngan_train(4001, 32, 200)  #4000번 반복되고(+1을 해 주는 것에 주의), 배치 사이즈는 32,  200번 마다 결과가 저장되게 하였습니다.\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if not os.path.exists(\"./gan_images\"):\n",
    "#    os.makedirs(\"./gan_images\")\n",
    "\n",
    "                              \n",
    "#생성자 모델\n",
    "generator = Sequential()\n",
    "#노드 128\n",
    "generator.add(Dense(128*4*4, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "#256 만들어야함 upsampling 2번(x4), input_dim은 100차원 벡터, 입력층에서 LeakyReLU\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((4, 4, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "#업샘플링(가로세로x2)\n",
    "generator.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "#업샘플링(가로세로x2)\n",
    "generator.add(Conv2D(1, kernel_size=3, padding='same', activation='tanh'))\n",
    "#출력층에서 tanh\n",
    "\n",
    "#판별자 모델\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=3, strides=2, input_shape=(16,16,1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "#노드 30% 꺼줌 dropout\n",
    "discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "#노드 30% 꺼줌 dropout\n",
    "discriminator.add(Flatten())\n",
    "#2차원 1차원으로\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "#참 거짓 0~1로 구분\n",
    "discriminator.trainable = False\n",
    "\n",
    "#생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "\n",
    "#신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "    (X_train, _), (_, _) = \n",
    "    X_train = X_train.reshape(X_train.shape[0], 16, 16, 1).astype('float32')\n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for i in range(epoch):\n",
    "        # 실제 데이터 판별자 입력\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "        #가상 이미지 판별자 입력\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "        #판별자와 생성자의 오차 계산\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "        print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        #중간 과정을 이미지로 저장해 주는 부분입니다\n",
    "        if i % saving_interval == 0:\n",
    "            #r, c = 5, 5\n",
    "            noise = np.random.normal(0, 1, (25, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # Rescale images 0 - 1\n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            count = 0\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                    axs[j, k].axis('off')\n",
    "                    count += 1\n",
    "            fig.savefig(\"gan_images/gan%d.png\" % i)\n",
    "\n",
    "gan_train(4001, 32, 200)  #4000번 반복, 배치 사이즈  32,  200번 마다 결과가 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
